{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM-notes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfoI1TXUd7ml"
      },
      "source": [
        "# SVM (Support Vector Machine)\n",
        "\n",
        "A Support Vector Machine (SVM) is a very powerful and versatile Machine Learning model, capable of performing linear or nonlinear classification, regression, and even outlier detection.\n",
        "\n",
        "## Linear SVM Classification\n",
        "\n",
        "![image 1](https://bit.ly/3FuY0rU)\n",
        "\n",
        "You can think of an SVM classifier as fitting the widest possible street (represented by the parallel dashed lines) between the classes. This is called large margin classification.\n",
        "\n",
        "**Support vectors** are points located on the edge of the street.\n",
        "\n",
        "### Difference Between Soft and Hard Margin Classification\n",
        "\n",
        "**hard margin** If we strictly impose that all instances be off the street and on the right side, this is called hard margin classification\n",
        "\n",
        "#### Issues with hard margin :\n",
        "*   First, it only works if the data is linearly separable\n",
        "*   and second it is quite sensi‐ tive to outliers.\n",
        "\n",
        "**soft margin** is keeping the wide enough to keep a balance bteween margin voilations, this is called soft margin\n",
        "\n",
        "* in sklearn we can control this balance by using C - hyperparameter: a smaller C value leads to wider street but more margin voilations.\n",
        "\n",
        "![image 2](https://bit.ly/3wWzIDQ)\n",
        "\n",
        "## Non Linear SVM Classification\n",
        "\n",
        "although linear svm classfication works well on many datasets, but sometimes it is not fissible to seperate them using a linear hyperplane so we use non-linear svm classification method.\n",
        "\n",
        "*   One approach to handling nonlinear datasets is to add more features, such as polynomial features\n",
        "*   or other is increase the dimension of the features given\n",
        "\n",
        "![image 3](https://bit.ly/3DwVpgc)\n",
        "\n",
        "\n",
        "### Polynomial Kernel\n",
        "\n",
        "Adding polynomial features is simple to implement and can work great with all sorts of Machine Learning algorithms (not just SVMs), but at a low polynomial degree it cannot deal with very complex datasets, and with a high polynomial degree it creates a huge number of features, making the model too slow.\n",
        "\n",
        "```\n",
        "from sklearn.svm import SVC poly_kernel_svm_clf = Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
        "        ])\n",
        "    poly_kernel_svm_clf.fit(X, y)\n",
        "\n",
        "```\n",
        "This code trains an SVM classifier using a 3rd-degree polynomial kernel.\n",
        "The hyperparameter *coef0* controls how much the model is influenced by high- degree polynomials versus low-degree polynomials.\n",
        "\n",
        "\n",
        "### Gaussian RBF Kernel\n",
        "\n",
        "![gaussian rbf](https://bit.ly/3oIn73q)\n",
        "\n",
        "```\n",
        "rbf_kernel_svm_clf = Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
        "        ])\n",
        "rbf_kernel_svm_clf.fit(X, y)\n",
        "```\n",
        "Increasing gamma makes the bell-shape curve narrower. γ acts like a regularization hyperparameter: if your model is overfitting, you should reduce it, and if it is under‐ fitting, you should increase it (similar to the C hyperparameter).\n",
        "\n",
        "\n",
        "## SVM Regression\n",
        "\n",
        "SVM is a quite versatile algorithm, it not only does support linear and non-linear classification, but also support linear and non-linear regression\n",
        "\n",
        "SVM Regression tries to fit as many instances as possible on the street while limiting margin violations (i.e., instances off the street). The width of the street is controlled by a hyperparameter ε\n",
        "\n",
        "![svm regression](https://bit.ly/3CpMPP3)\n",
        "\n",
        "## Under the Hood\n",
        "*derivation: will be added after first lecture (openboard)*\n",
        "\n"
      ]
    }
  ]
}